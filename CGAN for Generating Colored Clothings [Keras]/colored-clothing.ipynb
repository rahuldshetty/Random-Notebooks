{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"image_path = \"/kaggle/input/apparel-images-dataset/\"\nfolders = os.listdir(image_path)\nprint(folders)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset X [color, type]\nimg_shp = 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cloths = {}\ncolors = {}\ncol_id = 0\ncloth_id = 0\nfor folder in folders:\n    color, cloth = folder.split('_')\n    if color not in colors:\n        colors[color] = col_id\n        col_id += 1\n    if cloth not in cloths:\n        cloths[cloth] = cloth_id\n        cloth_id += 1\n        \nprint(colors, cloths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import io\nfrom skimage.transform import resize\n\nx = []\ny = []\ni = 0\nfor folder in folders:\n    color, cloth = folder.split('_')\n    cloth = cloths[cloth]\n    color = colors[color]\n    \n    path =  image_path + folder + \"/\"\n    for file in os.listdir(path):\n        print(i)\n        i+=1\n        fpath = path + file\n        x.append([color, cloth])\n        \n        # image load\n        img = resize(io.imread(fpath), (64,64,3))\n        y.append(img)\nx = np.array(x)\ny = np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rev_colors = {colors[k]:k for k in colors }\nrev_cloths = {cloths[k]:k for k in cloths }\ndef get_reverse_map(data):\n    return rev_colors[data[0]], rev_cloths[data[1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_img(image):\n    plt.axis(\"off\")\n    image = np.array(image).reshape((64,64,3))\n    plt.imshow(image)\n    plt.show()\n\nidx =  104\nx_sample = x[idx]\nprint(get_reverse_map(x_sample))\nplot_img(y[idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.optimizers import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_generator():\n    n_nodes = 128*8*8\n    \n    # Image shape = 28,28,1\n    z = Input(shape=(100,))      # latent vector = (100,1)\n    z_i = Dense(n_nodes)(z)\n    z_i = Reshape((8,8,128))(z_i)\n    \n    \n    y = Input(shape=(6,))      # Color shape = (6,1)\n    y_i = Dense(64)(y)  # 49,1\n    y_i = Reshape((8,8,1))(y_i) \n    \n    v = Input(shape=(5,))      # Cloth shape = (5,1)\n    v_i = Dense(64)(v)  # 49,1\n    v_i = Reshape((8,8,1))(v_i) \n    \n    merge = Concatenate()([z_i, y_i, v_i]) # Output: (7,7,130)\n    \n    out = Conv2DTranspose(128, 4, 2, padding='same')(merge) # (14,14,128)\n    out = LeakyReLU(alpha=0.2)(out)\n    \n    out = Conv2DTranspose(128, 4, 2, padding='same')(out) # (28,28,128)\n    out = LeakyReLU(alpha=0.2)(out)\n    \n    out = Conv2DTranspose(256, 4, 2, padding='same')(out) # (56,56,256)\n    out = LeakyReLU(alpha=0.2)(out)\n\n    \n    out = Conv2DTranspose(3, 7, 1, padding='same',activation='sigmoid')(out) # (64,64,3)\n    \n    model = Model([z,y, v],out)\n    model.summary()\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy',optimizer=opt)\n    return model\n    \ngen = build_generator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_discriminator(): \n    # Image shape = 28,28,1\n    x = Input(shape=(64,64,3))  \n    x_i = Conv2D(64,4,4,padding='same')(x)\n    x_i = ReLU()(x_i)\n    \n    x_i = Conv2D(128,4,2,padding='same')(x_i)\n    x_i = ReLU()(x_i)\n    \n    \n    y = Input(shape=(6,))      # label shape = (10,1)\n    y_i = Dense(64)(y)  # 49,1\n    y_i = Reshape((8,8,1))(y_i) \n    \n    v = Input(shape=(5,))      # Cloth shape = (5,1)\n    v_i = Dense(64)(v)  # 49,1\n    v_i = Reshape((8,8,1))(v_i) \n    \n    merge = Concatenate()([x_i, y_i, v_i]) # Output: (7,7,129)\n    out = Conv2D(256,4,2,padding='same')(merge)\n    \n    out = Flatten()(out)\n    \n    out = Dense(1024)(out) \n    \n    out = Dense(512)(out) \n    out = ReLU()(out)\n    \n    out = Dense(256)(out) \n    out = ReLU()(out)\n    \n    out = Dense(1, activation='sigmoid')(out) \n    \n    model = Model([x,y, v],out)\n    model.summary()\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy',optimizer=opt)\n    return model\n    \ndisc = build_discriminator()   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_gan(g,d):\n    d.trainable = False\n    # get generator inputs/outputs\n    z, y, v = g.input\n    x_g = g.output\n    \n    gan_output = d([x_g, y, v])\n    model = Model([z, y, v], gan_output)\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt)\n    model.summary()\n    return model\ngan = build_gan(gen, disc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\ndef generate_real_samples(image, colors, cloths, n_samples):\n    ix = np.random.randint(0, image.shape[0], n_samples)\n    x, colors, cloths = image[ix], colors[ix], cloths[ix]\n    y_ones = np.ones((n_samples,1))\n    return [x, colors, cloths], y_ones","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_latent_points(latent_dim, n_samples):\n    x_input = np.random.randn(latent_dim*n_samples)\n    z_input = x_input.reshape(n_samples, latent_dim)\n    colors = to_categorical(np.random.randint(0, 6, n_samples),num_classes=6)\n    cloths = to_categorical(np.random.randint(0, 5, n_samples),num_classes=5)\n    return [z_input, colors, cloths]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use the generator to generate n fake examples, with class labels\ndef generate_fake_samples(generator, latent_dim, n_samples):\n    z_input, colors_input, cloths_input  = generate_latent_points(latent_dim, n_samples)\n    images = generator.predict([z_input, colors_input, cloths_input])\n    y = np.zeros((n_samples, 1))\n    return [images, colors_input, cloths_input], y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(g, d, gan, dataset, latent_dim, n_epochs=100, n_batch=128):\n    bat_per_epo = int(dataset[0].shape[0]/n_batch)\n    half_batch = int(n_batch / 2)\n    for i in range(n_epochs):\n        print(\"Epoch:\", i)\n        for j in range(bat_per_epo):\n            # get random real samples\n            [x_real, color_labels_real, cloth_labels_real],y_real = generate_real_samples(dataset[0], dataset[1], dataset[2], half_batch)\n            # train discriminator\n            d_loss1 = d.train_on_batch([x_real, color_labels_real, cloth_labels_real], y_real)\n            \n            # Generate fake samples\n            [x_fake, color_labels, cloth_labels], y_fake = generate_fake_samples(g, latent_dim, half_batch)\n            # train discriminator\n            d_loss2 = d.train_on_batch([x_fake, color_labels, cloth_labels], y_fake)\n            \n            # prepare latent points \n            z_input, colors,cloths = generate_latent_points(latent_dim,n_batch)\n            y_gan = np.ones((n_batch,1))\n            \n            # train gan\n            g_loss = gan.train_on_batch([z_input, colors, cloths], y_gan)\n            if j % 10 == 0:\n                print(\"D1 Loss:\",d_loss1, \"D2 Loss:\",d_loss2,\"GAN Loss:\",g_loss)\n            \n    g.save('cgan_generator.h5')\n    d.save('cgan_discriminator.h5')\n    gan.save('gan.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = y\ncolors_labels, cloth_labels  = to_categorical(x[:,0], num_classes=6), to_categorical(x[:,1], num_classes=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(colors_labels.shape, cloth_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(gen, disc, gan, [train_features, colors_labels, cloth_labels], 100, n_epochs = 500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_sample(g, n=30, latent=100):\n    colors = to_categorical(np.array([x for x in range(0,6)]),num_classes=6)\n    cloths = to_categorical(np.array([x for x in range(0,5)]),num_classes=5)\n    z_vec = generate_latent_points(latent, 1)[0]\n    columns = 10\n    rows = n\n    fig=plt.figure(figsize=(64, 64))\n    k = 1\n    for j in range(6):\n        for i in range(5):\n            z_vec = z_vec.reshape((1,100,1))\n            color = colors[j].reshape((1,6,1))\n            cloth = cloths[i].reshape((1,5,1))\n            result = g.predict([z_vec,color,cloth])[0]\n            ax = fig.add_subplot(rows, columns, k)\n            ax.title.set_text(\" \".join(get_reverse_map([j, i])))\n            plt.imshow(result)\n            k += 1\n    plt.show()\n    \ngenerate_sample(gen)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}